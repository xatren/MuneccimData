# GeliÅŸmiÅŸ Veri HazÄ±rlama ve KÃ¼meleme Pipeline'Ä±

Bu proje, veri hazÄ±rlama, kÃ¼meleme optimizasyonu ve gerÃ§ek zamanlÄ± kÃ¼meleme analizi iÃ§in kapsamlÄ± bir Ã§Ã¶zÃ¼m sunar. Sistem, hem statik veri kÃ¼meleri hem de streaming veri akÄ±ÅŸlarÄ± iÃ§in optimize edilmiÅŸ algoritmalar iÃ§erir.

## ðŸ”¬ Bilimsel AltyapÄ±

### 1. Veri HazÄ±rlama ve Ã–n Ä°ÅŸleme

#### 1.1 Eksik Veri Analizi
- **Matematiksel Temel**: Eksik veri oranÄ± (Ï) hesaplamasÄ±:
  ```
  Ï = (n_missing / n_total) Ã— 100
  ```
- **Doldurma Stratejileri**:
  - SayÄ±sal deÄŸiÅŸkenler iÃ§in: Î¼ (ortalama), Î· (medyan)
  - Kategorik deÄŸiÅŸkenler iÃ§in: mod (en sÄ±k deÄŸer)

#### 1.2 AykÄ±rÄ± DeÄŸer Tespiti
- **IQR (Interquartile Range) YÃ¶ntemi**:
  ```
  IQR = Q3 - Q1
  alt_sÄ±nÄ±r = Q1 - k Ã— IQR
  Ã¼st_sÄ±nÄ±r = Q3 + k Ã— IQR
  ```
  Burada k genellikle 1.5 olarak alÄ±nÄ±r.

- **Z-Score YÃ¶ntemi**:
  ```
  z = (x - Î¼) / Ïƒ
  ```
  |z| > threshold olan deÄŸerler aykÄ±rÄ± kabul edilir.

#### 1.3 DaÄŸÄ±lÄ±m Normalizasyonu
- **Yeo-Johnson Transformasyonu**:
  ```
  f(x;Î») = {
    ((x + 1)^Î» - 1) / Î»,     x â‰¥ 0, Î» â‰  0
    ln(x + 1),               x â‰¥ 0, Î» = 0
    -((-x + 1)^(2-Î») - 1) / (2-Î»), x < 0, Î» â‰  2
    -ln(-x + 1),            x < 0, Î» = 2
  }
  ```

### 2. KÃ¼meleme AlgoritmalarÄ± ve Optimizasyon

#### 2.1 K-Means KÃ¼meleme
- **Matematiksel FormÃ¼lasyon**:
  ```
  minimize Î£ Î£ ||x_i - Î¼_k||Â²
  ```
  Burada x_i veri noktalarÄ±, Î¼_k kÃ¼me merkezleridir.

- **Optimizasyon Metrikleri**:
  - Silhouette Skoru (S):
    ```
    s(i) = (b(i) - a(i)) / max{a(i), b(i)}
    ```
    Burada a(i) iÃ§-kÃ¼me mesafesi, b(i) en yakÄ±n komÅŸu kÃ¼meye olan mesafedir.
  
  - Calinski-Harabasz Indeksi:
    ```
    CH = [tr(B_k)/(k-1)] / [tr(W_k)/(n-k)]
    ```
    B_k: kÃ¼meler arasÄ± kovaryans matrisi
    W_k: kÃ¼me iÃ§i kovaryans matrisi

#### 2.2 DBSCAN (Density-Based Spatial Clustering)
- **Parametre Optimizasyonu**:
  - Îµ (epsilon): KomÅŸuluk yarÄ±Ã§apÄ±
  - MinPts: Minimum nokta sayÄ±sÄ±
  ```
  core_point := |N_Îµ(p)| â‰¥ MinPts
  ```

#### 2.3 HiyerarÅŸik KÃ¼meleme
- **BaÄŸlantÄ± Kriterleri**:
  - Ward Minimum Varyans:
    ```
    d(u,v) = âˆš[(|v|+|s|)/(|v|+|s|+|t|) Ã— dÂ²(v,s) + 
              (|v|+|t|)/(|v|+|s|+|t|) Ã— dÂ²(v,t) -
              |v|/(|v|+|s|+|t|) Ã— dÂ²(s,t)]
    ```

### 3. GerÃ§ek ZamanlÄ± KÃ¼meleme (Streaming)

#### 3.1 Mini-Batch K-Means
- **GÃ¼ncelleme FormÃ¼lÃ¼**:
  ```
  c_t = c_{t-1} Ã— (1 - 1/n_t) + x_t Ã— (1/n_t)
  ```
  Burada c_t merkez gÃ¼ncellemesi, n_t atama sayÄ±sÄ±dÄ±r.

#### 3.2 Incremental Learning
- **Online PCA**:
  ```
  Î£_t = (1 - Î±)Î£_{t-1} + Î±x_tx_t^T
  ```
  Î± Ã¶ÄŸrenme oranÄ±dÄ±r.

## ðŸ›  Teknik Ã–zellikler

### API Endpoints

#### 1. Model YÃ¶netimi
- `POST /load_model`: Model yÃ¼kleme
  ```json
  {
    "model_path": "string",
    "method": "static|streaming"
  }
  ```

#### 2. Tahmin ve GÃ¼ncelleme
- `POST /predict`: KÃ¼me tahminleri
- `POST /partial_fit`: Streaming model gÃ¼ncelleme

### Veri FormatlarÄ±

#### 1. GiriÅŸ Verisi
```json
{
  "data": [
    {"features": [float, ...]}
  ]
}
```

#### 2. Ã‡Ä±kÄ±ÅŸ FormatÄ±
```json
{
  "labels": [int, ...],
  "metrics": {
    "cluster_distribution": [int, ...],
    "total_samples": int
  }
}
```

## ðŸ“Š Performans Metrikleri

### 1. KÃ¼meleme Kalitesi
- Silhouette Skoru: [-1, 1]
- Calinski-Harabasz Indeksi: [0, âˆž)
- Davies-Bouldin Indeksi: [0, âˆž)

### 2. Hesaplama KarmaÅŸÄ±klÄ±ÄŸÄ±
- K-Means: O(kndi)
  - k: kÃ¼me sayÄ±sÄ±
  - n: Ã¶rnek sayÄ±sÄ±
  - d: boyut
  - i: iterasyon sayÄ±sÄ±
- DBSCAN: O(n log n)
- HiyerarÅŸik: O(nÂ²)

## ðŸš€ Kurulum ve KullanÄ±m

### 1. Gereksinimler
```bash
pip install -r requirements.txt
```

### 2. Ã–rnek KullanÄ±m
```python
from data_preparation import DataPreparation
from clustering import ClusteringOptimizer

# Veri hazÄ±rlama
prep = DataPreparation()
df = prep.load_data("data.csv")
df_processed = prep.handle_missing_values(df, strategy={'numeric': 'mean'})

# KÃ¼meleme optimizasyonu
optimizer = ClusteringOptimizer()
results = optimizer.find_optimal_kmeans(X, k_range=range(2, 11))
```

### 3. API Servisi
```bash
uvicorn api_service:app --reload
```

## ðŸ“š Referanslar

1. Ester, M., et al. (1996). "A Density-Based Algorithm for Discovering Clusters"
2. Lloyd, S. (1982). "Least squares quantization in PCM"
3. Ward Jr, J. H. (1963). "Hierarchical Grouping to Optimize an Objective Function"
4. Yeo, I. K., & Johnson, R. A. (2000). "A New Family of Power Transformations to Improve Normality"

## ðŸ¤ KatkÄ±da Bulunma

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request 